---
title: "Introduction to tidyjson"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to tidyjson}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(collapse = T, comment = "#>")
options(tibble.print_min = 4L, tibble.print_max = 4L)
library(tidyjson)
```

[JSON](http://json.org/) (JavaScript Object Notation) is a lightweight and 
flexible data format that is easy for humans to read and for machines to parse. 
JSON has become a common format used in:

* Public APIs (e.g., [Twitter](https://dev.twitter.com/rest/public))

* NoSQL databases as a document format (e.g., [MongoDB](https://www.mongodb.org/))

* Relational databases as a new column type (e.g., [PostgreSQL](http://www.postgresql.org/docs/9.4/static/datatype-json.html))

Tidyjson provides a grammar for turning JSON data into tidy
data frames that are easy to work with in the [tidyverse](https://github.com/hadley/tidyverse).

## Why use tidyjson?

Several libraries exist for working with JSON data in R, such as
[rjson](http://cran.r-project.org/web/packages/rjson/index.html),
[rjsonio](http://cran.r-project.org/web/packages/RJSONIO/index.html) and
[jsonlite](http://cran.r-project.org/web/packages/jsonlite/index.html). These
libraries transform JSON data automatically into nested R lists or complex data 
frames. However, working with these complex objects can be difficult.

The tidyjson package takes a different approach to structuring JSON data into 
tidy data frames. Similar to 
[tidyr](http://cran.r-project.org/web/packages/tidyr/index.html), tidyjson 
builds a grammar for manipulating JSON into a tidy table structure.

Tidyjson is based on the following principles:

* Work on a single JSON document, or on a collection of related documents

* Create pipelines with `%>%`, producing code that can be read from left to 
right

* Guarantee the structure of the data produced, even if the input JSON
structure changes (with the exception of `spread_all`)

* Work with arbitrarily nested arrays or objects

* Handle 'ragged' arrays and / or objects (varying lengths by document)

* Allow for extraction of data in values or object names

* Ensure edge cases are handled correctly (especially empty data)

* Integrate seamlessly with `dplyr`, allowing `tbl_json` objects to pipe in and
out of `dplyr` verbs where reasonable

## A simple example

A simple example of how tidyjson works is as follows:

```{r, message = FALSE}
library(dplyr)

# Define a simple people JSON collection
people <- c('{"age": 32, "name": {"first": "Bob",   "last": "Smith"}}',
            '{"age": 54, "name": {"first": "Susan", "last": "Doe"}}',
            '{"age": 18, "name": {"first": "Ann",   "last": "Jones"}}')

# Tidy the JSON data
people %>% spread_all
```

This produces a `tbl_json` object, where each row corresponds to an element of
the `people` vector (a "document" in tidyjson). The JSON attribute of the
`tbl_json` object is shown first, then the columns of the tibble are shown - a `document.id` indicating which document the row originated in, and then the age 
and name columns that `spread_all` created.

## A more complex example

The tidyjson package really shines in a more complex example. Consider the 
`worldbank` data included in the tidyjson package.

```{r}
worldbank %>% str
```

It is a `r length(worldbank)` length character vector of projects funded by
the world bank. We can quickly expand all simple columns using `spread_all`

```{r}
worldbank %>% spread_all
```

And we can limit the coluns produced by calling `dplyr::select` after

```{r}
worldbank %>% spread_all %>% select(regionname, totalamt)
```

But worldbank also contains arrays, which cannot be naively spread into new
columns. We can use `gather_object` to gather all name-value paris by name,
and then `json_types` to identify the type of JSON stored under each value, and
`dplyr::count` to aggregate across documents:

```{r, echo = FALSE, message = FALSE}
options(tibble.print_min = 10L, tibble.print_max = 10L)
```

```{r}
worldbank %>% gather_object %>% json_types %>% count(name, type)
```

```{r, echo = FALSE, message = FALSE}
options(tibble.print_min = 4L, tibble.print_max = 4L)
```

It appears that `"majorsector_percent"` is an array, and so we can use
`enter_object` to enter into it:

```{r}
worldbank %>% enter_object("majorsector_percent")
```

and `gather_array` to gather it by index

```{r}
worldbank %>% enter_object("majorsector_percent") %>% gather_array
```

We can then `spread_all` again to capture the name-value pairs stored in each
object

```{r}
worldbank %>% 
  enter_object("majorsector_percent") %>% gather_array %>% spread_all
```

By combining with our initial top-level `spread_all`, we can aggregate funding
dollars by sector by region:

```{r}
worldbank %>%
  spread_all %>% select(region = regionname, funding = totalamt) %>%
  enter_object("majorsector_percent") %>% gather_array %>% 
  spread_all %>% rename(sector = Name, percent = Percent) %>%
  group_by(region, sector) %>%
  summarize(funding = sum(funding * percent))
```

Next Steps:
1. Move the verbs section up, and call it functions instead
1. Update the table
1. Talk about common patterns rather than every function

## Getting started with JSON data

The first step in using tidyjson is to get your data into a `tbl_json` object.
All tidyjson functions automatically coerce objects into `tbl_json` if they are
not already, so you may be able to just start manipulating your data directly.

But if not, you can use `as.tbl_json` directly. Here are examples for common
scenarios:

### Character vector

The simplest case is when your JSON data is already in R as a character vector,
like the `worldbank` data:

```{r}
worldbank %>% as.tbl_json
```

If this generates errors, then likely your JSON data is malformed:

```{r, error = TRUE}
bad_json <- '{"key": "value"'
bad_json %>% as.tbl_json
```

tidyjson uses `jsonlite::fromJSON` to parse the JSON, and so will print out a
useful error message.

### Single array

Many APIs will return multiple documents in a single array, like the `issues`
data from github.

```{r}
issues %>% as.tbl_json
```

A single call to gather_array makes this data look like the
`worldbank` data:

```{r}
issues %>% as.tbl_json %>% gather_array
```

### List

If your JSON is a list of character strings, you can use `purrr::flatten_chr'
to flatten it into a character vector and then proceed as usual:

```{r}
library(purrr)
list('1', '2') %>% flatten_chr %>% as.tbl_json
```

### Data frame

If you extracted JSON from a table in a database into a data frame, then likely 
you already have other columns in the data frame you would like to retain. You
can use then `json.column` argument to `as.tbl_json` to specify which column
contains the JSON of interest:

```{r}
df <- data_frame(id = 1:2, json = list('[1, 2]', '[3, 4]'))
df %>% as.tbl_json(json.column = "json")
```

### File

If your JSON is in a file, like in the [jsonlines](http://jsonlines.org/) 
format, then you can use `read_json` to read the file into a `tbl_json` object
directly.

### JSON included in the package

The tidyjson package comes with several JSON example datasets:

* `commits`: commit data for the dplyr repo from github API

* `issues`: issue data for the dplyr repo from github API

* `worldbank`: world bank funded projects from 
[jsonstudio](http://jsonstudio.com/resources/)

* `companies`: startup company data from 
[jsonstudio](http://jsonstudio.com/resources/)

Each dataset has some example tidyjson queries in `help(commits)`, 
`help(issues)`, `help(worldbank)` and `help(companies)`.

## Functions

The rest of tidyjson is comprised of various verbs with operate on `tbl_json`
objects and return `tbl_json` objects. They are meant to be used in a pipeline
with the `%>%` operator.

Note that these verbs all operate on *both* the underlying data.frame and the
JSON, iteratively moving data from the JSON into the data.frame. Any
modifications of the underlying data.frame outside of these operations
may produce unintended consequences where the data.frame and JSON become out of
synch.

The following table provides a reference of how each verb is used and what
(if any) effect it has on the data.frame rows and columns and on the associated
JSON.

| Verb                | Use                            | Row Effect           | Column Effect    | JSON Effect  |
|:--------------------|:-------------------------------|:---------------------|:-----------------|:-------------|
| `json_types()`      | Identify JSON structure        | none                 | type column      | none         |
| `gather_array()`    | Stack JSON array               | Repeats rows         | index column     | enter array  |
| `gather_object()`   | Stack a {"name": value} object | Repeats rows         | name column       | enter object |
| `spread_values()`   | Create new columns from values | none                 | N value columns  | none         |
| `append_values_X()` | Append all values of a type    | none                 | column of type X | none         |
| `enter_object()`    | Enter into an object by name   | Keeps rows with name | none             | enter object |
| `json_lengths()`    | Identify JSON length           | none                 | length column    | none         |

### Identify JSON structure with `json_types()`

One of the first steps you will want to take is to investigate the structure of
your JSON data. The function `json_types()` inspects the JSON associated with 
each row of the data.frame, and adds a new column (`type` by default) that 
identifies the type according to the [JSON standard](http://json.org/).

```{r}
c('{"a": 1}', '[1, 2]', '"a"', '1', 'true', 'null') %>% json_types
```

This is particularly useful for inspecting your JSON data types, and can added
after `gather_array()` (or `gather_object()`) to inspect the types of the elements
(or values) in arrays (or objects).

### Stack a JSON array with `gather_array()`

Arrays are sometimes vectors (fixed or varying length integer, character or 
logical vectors). But they also often contain lists of other objects (like
a list of purchases for a user). The function `gather_array()` takes JSON arrays
and duplicates the rows in the data.frame to correspond to the indices of the 
array, and puts the elements of the array into the JSON attribute. 
This is equivalent to "stacking" the array in the data.frame, and lets you 
continue to manipulate the remaining JSON in the elements of the array.

```{r}
'[1, "a", {"k": "v"}]' %>% gather_array %>% json_types
```

This allows you to *enter into* an array and begin processing it's elements
with other tidyjson functions. It retains the array.index in case the relative
position of elements in the array is useful information.

### Stack a {"name": value} object with `gather_object()`

Similar to `gather_array()`, `gather_object()` takes JSON objects and duplicates 
the rows in the data.frame to correspond to the names of the object, and puts the 
values of the object into the JSON attribute.

```{r}
'{"name": "bob", "age": 32}' %>% gather_object %>% json_types
```

This allows you to *enter into* the names of the objects just like `gather_array`
let you enter elements of the array.

### Create new columns with JSON values with `spread_values()`

Adding new columns to your `data.frame` is accomplished with `spread_values()`, 
which lets you dive into (potentially nested) JSON objects and extract specific 
values. `spread_values()` takes `jstring()`, `jnumber()` or `jlogical()` 
function calls as arguments in order to specify the type of the data that should 
be captured

These values can be of varying types at varying depths, e.g.,

```{r}
'{"name": {"first": "bob", "last": "jones"}, "age": 32}' %>%
  spread_values(
    first.name = jstring("name", "first"), 
    age = jnumber("age")
  )
```

### Append all values of a specified type with `append_values_X()`

The `append_values_X()` functions let you take the remaining JSON and add it as
a column X (for X in "string", "number", "logical") insofar as it is of the
JSON type specified. For example:

```{r}
'{"first": "bob", "last": "jones"}' %>% 
  gather_object() %>%
  append_values_string()
```

Any values that do not conform to the type specified will be NA in the resulting
column. This includes other scalar types (e.g., numbers or logicals if you are
using `append_values_string()`) and *also* any rows where the JSON is still an
object or an array.

### Dive into a specific object "name" with `enter_object()`

For complex JSON structures, you will often need to navigate into nested objects
in order to continue structuring your data. The function `enter_object()` lets 
you dive into a specific object name in the JSON attribute, so that all further 
tidyjson calls happen inside that object (all other JSON data outside the object 
is discarded). If the object doesn't exist for a given row / index, then that 
data.frame row will be discarded.

```{r}
c('{"name": "bob", "children": ["sally", "george"]}', '{"name": "anne"}') %>% 
  spread_values(parent.name = jstring("name")) %>%
  enter_object("children") %>% 
  gather_array %>% 
  append_values_string("children")
```

This is useful when you want to limit your data to just information found in
a specific name.

### Identify length of JSON objects with `json_lengths()`

When investigating JSON data it can be helpful to identify the lengths of the
JSON objects or arrays, especialy when they are 'ragged' across documents:

```{r}
c('[1, 2, 3]', '{"k1": 1, "k2": 2}', '1', {}) %>% json_lengths
```

## Strategies

When beginning to work with JSON data, you often don't have easy access to a
schema describing what is in the JSON. One of the benefits of document oriented
data structures is that they let developers create data without having to worry
about defining the schema explicitly.

Thus, the first step is to understand the structure of the JSON. Begin by 
visually inspecting a single record with `jsonlite::prettify()`.

```{r}
library(jsonlite)
'{"name": "value", "array": [1, 2, 3]}' %>% prettify
```

However, for complex data or large JSON structures this can be tedious. Instead,
use `gather_object`, `json_types` and `json_lengths` to summarize the data:

```{r}
'{"name": "value", "array": [1, 2, 3]}' %>% 
  gather_object %>% json_types %>% json_lengths
```

You can repeat this as you move through the JSON data using `enter_object()` to
summarize nested structures as well.

Once you have an understanding of how you'd like the data to be assembled, begin
creating your tidyjson pipeline. Use `enter_objects()` and `gather_array()` to
navigate the JSON and stack any arrays, and use `spread_values()` to get at 
(potentially nested) name-value pairs along the way.

Before entering any objects, make sure you first use `spread_values()` to 
capture any top level identifiers you might need for analytics, summarization or
relational uses downstream. If an identifier doesn't exist, then you can always
fall back on the `as.tbl_json` generated document.id column.

If you encounter data where information is encoded in both names and values,
then consider using `gather_object()` and `append_values_X()` where `X` is the type
of JSON scalar data you expect in the values.

Note that there are often situations where there are multiple arrays or objects
of differing types that exist at the same level of the JSON hierarchy. In this
case, you need to use `enter_object()` to enter each of them in *separate*
pipelines to create *separate* `data.frames` that can then be joined 
relationally.

Finally, don't forget that once you are done with your JSON tidying, you can
use [dplyr](http://github.com/hadley/dplyr) to continue manipulating the
resulting data. `dplyr::filter`, `dplyr::arrange` and `dplyr::mutate` can be
used and will preserve the JSON attribute for further tidyjson manipulation.
The same is true for the `[` operator. Other `dplyr` functions will destroy
the JSON attribute, so you will no longer be able to manipulate the JSON data.

### World bank example

Included in the tidyjson package is a `r length(worldbank)` record sample, 
`worldbank`, which contains a subset of the JSON data describing world bank 
funded projects from [jsonstudio](http://jsonstudio.com/resources/).

First, let's take a look at a single record. We can use `jsonlite::prettify` to
make the JSON easy to read:

```{r}
library(jsonlite)
worldbank[1] %>% prettify
```

An interesting objects is "majorsector_percent", which appears to capture the
distribution of each project by sector. We also have several funding amounts,
such as "totalamt", which indicate how much money went into each project.

Let's grab the "totalamt", and then gather the array of sectors and their
percent allocations.

```{r}
amts <- worldbank %>%
  spread_values(
    total = jnumber("totalamt")
  ) %>% 
  enter_object("majorsector_percent") %>% gather_array %>%
  spread_values(
    sector = jstring("Name"),
    pct = jnumber("Percent")
  ) %>%
  mutate(total.m = total / 10^6) %>%
  select(document.id, sector, total.m, pct) %>%
  tbl_df 
amts
```

Let's check that the "pct" column really adds up to 100 by project:

```{r}
amts %>% 
  group_by(document.id) %>%
  summarize(pct.total = sum(pct)) %>%
  group_by(pct.total) %>%
  tally
```

It appears to always add up to 100. Let's also check the distribution of
the total amounts.

```{r}
summary(amts$total.m)
```

Many are 0, the mean is $80m and the max is over $1bn.

Let's now aggregate by the sector and compute, on a dollar weighted basis,
where the money is going by sector:

```{r}
amts %>%
  group_by(sector) %>%
  summarize(
    spend.portion = sum(total.m * pct / 100)
  ) %>%
  ungroup %>%
  mutate(spend.dist = spend.portion / sum(spend.portion)) %>%
  arrange(desc(spend.dist))
```

### Companies example

Also included in the tidyjson package is a `r length(companies)` record sample, 
`companies`, which contains a subset of the JSON data describing startups from 
[jsonstudio](http://jsonstudio.com/resources/).

Instead of using `jsonlite::prettify`, let's quickly summarize the names using 
tidyjson and visualize the results:

```{r, fig.width = 7, fig.height = 6}
library(ggplot2)
object_stats <- companies %>% 
  gather_object %>% json_types %>% count(name, type)
object_stats
ggplot(object_stats, aes(name, n, fill = type)) +
  geom_bar(stat = "identity", position = "stack") +
  coord_flip()
```

Suppose we are interested in exploring the funding round data. Let's examine
it's structure:

```{r, fig.width = 7, fig.height = 2}
companies %>%
  enter_object("funding_rounds") %>%
  gather_array %>% 
  gather_object %>% json_types %>% count(name, type) %>%
  ggplot(aes(name, n, fill = type)) +
    geom_bar(stat = "identity", position = "stack") +
    coord_flip()
```

Now, referencing the above visualizations, we can structure some of the data for 
analysis:

```{r}
rounds <- companies %>%
  spread_values(
    id = jstring("_id", "$oid"),
    name = jstring("name"),
    category = jstring("category_code")
  ) %>%
  enter_object("funding_rounds") %>%
  gather_array %>%
  spread_values(
    round = jstring("round_code"),
    raised = jnumber("raised_amount")
  )
rounds %>% glimpse
```

Now we can summarize by category and round how much is raised on average by
round:

```{r, fig.width = 7, fig.height = 2}
rounds %>%
  filter(
    !is.na(raised),
    round %in% c('a', 'b', 'c'),
    category %in% c('enterprise', 'software', 'web')
  ) %>%
  group_by(category, round) %>%
  summarize(raised = mean(raised)) %>%
  ggplot(aes(round, raised / 10^6, fill = round)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    labs(y = "Raised (m)") +
    facet_grid(. ~ category)
```

## Future work

This package is still a work in progress. Significant additional features we
are contemplating include:

- Summarizing JSON structures and visualizing them to make working with new JSON
easier
- Keeping the JSON in a parsed C++ data structure, and using rcpp to speed up
the manipulation of JSON
- Push computations to document oriented databases like MongoDB
